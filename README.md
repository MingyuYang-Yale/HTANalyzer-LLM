# spatiAlytica: Large Language Model for Analyzing HTAN Spatial Transcriptomics Data 

2024 Human Tumor Atlas Network Data Jamboree

November 6, 2024 - November 8, 2024

## Team members
**Team Leader**: Arun Das (University of Pittsburgh)

**Tech Lead**: Krithika Bhuvaneshwar (Frederick National Lab)

**Writers**:
- Jeanna Arbesfeld-Qiu (Harvard Medical School)
- Sanna Madan (National Cancer Institute)
- Noam Gaiger (Yale University)
  
**Members**:
- Ashish Mahabal (Caltech)
- Khoa Huynh (Virginia Commonwealth University)
- Mingyu Yang (Yale University)

## Background
*In situ* spatial transcriptomic (ST) technologies are a breakthrough class of methods that have redefined cancer biology research by providing insight into tumor microenvironment structure, organization, and heterogeneity. ST data have also allowed researchers to understand cell-cell signaling, such as in the context of the tumor microenvironment or the formation of developmental gradients. 

## What's the problem?
A growing number of spatial databases are being generated and are publicly available, yet navigating them can be challenging. For example, the Human Tumor Atlas Network (HTAN) is a valuable resource for biomedical researchers; however, making the data more easily accessible will potentiate its effective use. The large-scale and complex data generated by ST requires the development of specific tools for data analysis and interpretability. Currently, such tools require the computational expertise of a trained bioinformatician and close collaboration between wet-lab and dry-lab scientists.

## Our solution: spatiAlytica

SpatiAlytica is a multiagent large language model specifically designed to analyze spatial transcriptomic data from the Human Tumor Atlas Network (HTAN). SpatiAlytica allows users to interact with datasets on HTAN using conversational, natural language queries, making spatial transcriptomics analysis accessible to those with limited expertise in bioinformatics.

## Approach
Our approach uses three agents to allow for:
- Data integration with HTAN resources
- Bioinformatics analysis using standard Python packages
- Interactive chat interface providing human-friendly output

A reasoning engine directs the user's queries to the correct agent.
<div style="text-align: center;">
  <img width="617" alt="image" src="https://github.com/user-attachments/assets/dc634dd7-6013-4b68-94c8-089ca1396378">
  <img width="546" alt="image" src="https://github.com/user-attachments/assets/6665cbd9-34cb-49fb-9d17-95cf8710c8a8">
</div>

## Examples of questions you can ask spatiAlytica:
* Download all datasets in HTAN with 10x Visium spatial information for melanoma.
* What is the expression level of gene x in sample y?
* Show me the spatial location of the malignant cells.

## Installation

### Platform Requirements
spatiAlytica is designed to run on Google Cloud Platform's Vertex AI. Users should have a corresponding project ID and billing info.

### Dependencies
Required Python packages:
```python
synapseclient==4.6.0
scanpy==1.10.3
squidpy==1.6.1
pandas==2.2.2
matplotlib==3.7.1
google==2.0.3
vertexai==1.70.0
anndata-0.11.0
numpy==1.26.4
```

### Authentication Setup

1. Create a Synapse account and [generate a personal authentication token](https://accounts.synapse.org/authenticated/personalaccesstokens?appId=synapse.org) with full view, download, and modify permissions.
2. Use the token in your code:

```python
import synapseclient
syn = synapseclient.login(authToken="your_token_here")
```

### Required Imports
```
import pandas_gbq
from google.cloud import bigquery
import pandas as pd
import base64
import vertexai
from vertexai.generative_models import GenerativeModel, Part, SafetySetting
import scanpy, squidpy
import matplotlib.pyplot as plt
```

### Vertex AI Setup
```
vertexai.init(project="your_project_id_here", location="us-central1")
model = GenerativeModel("gemini-1.5-flash-002")
```
## Our workflow

To create each agent, we engineered prompts based on data and metadata structure, tutorial examples for single-cell RNA-seq and 10X Visium data from Python packages (e.g. [SquidPy](https://squidpy.readthedocs.io/en/stable/notebooks/tutorials/index.html), [ScanPy](https://scanpy-tutorials.readthedocs.io/en/latest/spatial/basic-analysis.html), and [COMMOT](https://commot.readthedocs.io/en/latest/tutorials.html)), and iterative LLM-based optimization of prompts. The code for each agent can be found on the following 

Agent 1: [agent1.ipynb](https://github.com/NCI-HTAN-Jamborees/spatiAlytica-LLM/blob/main/agent1.ipynb)

Agent 2: 

Agent 3: 

### Issues we encountered

- While using Google CoLab notebooks, we occasionally ran into an error regarding the CuPy library, which prevented import of various python packages. We solved this by running the following line in terminal.
  ```
  sudo apt-get install libnvidia-compute-550
  ```
- The output from the spatiAlytica can be stochastic. We attempted to mitigate this by reducing the temperature of the LLM to 0.3 - 0.5 and adding additional detail to the prompts.

### Future Directions
- Creating a recursive error-handling agent to debug code generated from Agent 1 and Agent 2.
- Improve user functionality by developing a "chatbot" frontend and developing a package for users to easily download spatiAlytica.
- Agent 1 (Data Integration) could be improved by adding prompts related to clinical metadata available on HTAN google buckets.
- Testing different LLM APIs (e.g. OpenAI, Claude)
- Currently, spatiAlytica is only designed for 10X Visium analysis and we hope to expand ST analysis to additional technologies and bioinformatics tools.
